\section{Motivation} \label{chpt:Einleitung_Motivation}

% Ich bin ein Unterkapitel
Durch die stetige Digitalisierung wird immer häufiger auf Lösungen zurückgegriffen, die verschiedene Branchen und Lebensbereiche unterstützen, vereinfachen und sogar erweitern. Von der Medizin, mit beispielsweiße Diagnoseverfahren für die Krankheitserkennung, bis hin zur Automobilindustrie mit teils selbst-fahrenden Kraftfahrzeugen, gewinnt das Fachgebiet des 'maschinellen Lernens' immer mehr an Bedeutung. Trotz des großen Potenzials entstehen auch immer häufigere und größere Herausforderungen, insbesondere mit dem Hinblick auf Sicherheit und Robustheit dieser Systeme.

Diese Arbeit legt den Fokus auf die Herausforderung der Verdeutlichung  von Sicherheits- und Robustheitsimplementierungen in Bild-Klassifikationsmodellen. In einem globalen System, in dem immer mehr Aspekte des täglichen Lebens in die 'Hände' von KI-Systemen gegeben werden, ist es umso wichtiger, diese im Anbetracht auf Sicherheit zu implementieren, wie auch zu überwachen. Eine Unsicherheit eines Systems kann hierbei schon zu Verletzungen des Datenschutzes einzelner Personen führen. Daher wird diese Arbeit gesondert  Angriffsvektoren und Bedrohungen von Klassifikationsmodellen behandeln.

Darüber hinaus werden einige innovative Ansätze zur Bekämpfung möglicher Angriffsvektoren und Schwachstellen aufgezeigt, die sowohl Sicherheit, als auch Robustheit von neuronalen Netzen erhöhen. Insgesamt soll diese Arbeit dazu beitragen, ein grundlegendes Verständis für Angriffe, deren Auswirkungen, wie auch Verteidigungsmaßnahmen dem Leser zu liefern. 

