\section{Angriffsmöglichkeiten auf Neuronale Netzwerke} \label{chpt:Stand_der_Technik_Angriffe}
Neuronale Netzwerke, obwohl leistungsfähig und vielseitig einsetzbar, eröffnen verschiedene Möglichkeiten für Angriffsvektoren, die von potenziellen Angreifern ausgenutzt werden können, um erheblichen Schaden anzurichten. Die Angriffe reichen von sogfältig konzipierten Manipulationen des Trainisngsprozesses bis hin zu raffinierten Methoden oder Modellinferenzen. Das ganze bringt  Konsequenzen für Entwickler und Unternehmen von Beeinträchtigung der KI-System-Verfügbarkeit bis hin zu gravierenden Datenschutzverletzungen von Involvierten mit sich.

% Data Poisoning (Trainingsprozess)
% Inferenz Angriffe (Model Inverison, Model Extraction, Membership inferenz)
% Adversarial Attacks
\subsection{Modell-Inversionsangriffe}
Hier soll was über Modell-Inversionsangriffe stehen (Bsp. usw.) ...
\subsubsection{Angriffsziel}
Hier soll was über Ziel von diesem Angriff geschreiben werden (Bsp. usw.) ...
\subsubsection{Angriffsvektoren}
Hier soll geschrieben werden, wie der Angriff ausgeführt werden kann (Bsp. usw.) ...
\subsubsection{Verteidigungsstrategien}{\label{diff_privacy}}
Hier sollen mögliche Verteidigungsstrategien beleuchtet werden ...
